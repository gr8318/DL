#Simple Perceptron Model for AND Logic Gate
import numpy as np
class Perceptron:
 def __init__(self, learning_rate=0.01, n_iters=10):
  self.lr = learning_rate
  self.n_iters = n_iters
  self.weights = None
  self.bias = None
 def fit(self, x, y):
  n_samples, n_features = x.shape
  self.weights = np.zeros(n_features)
  self.bias = 0
  for _ in range(self.n_iters):
   for idx, x_i in enumerate(x):
    linear_output = np.dot(x_i, self.weights) + self.bias
    y_predicted = self.activation(linear_output)
    update = self.lr * (y[idx] - y_predicted)
    self.weights += update * x_i
    self.bias += update
 def activation(self, x):
  return 1 if x >= 0 else 0
 def predict(self, x):
  linear_output = np.dot(x, self.weights) + self.bias
  y_predicted = np.array([self.activation(val) for val in linear_output])
  return y_predicted

if __name__ == "__main__":

 x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
 y = np.array([0, 0, 0, 1])
 p = Perceptron(learning_rate=0.1, n_iters=10)
 p.fit(x, y)
 predictions = p.predict(x)
 print("Predictions:", predictions)
